import sounddevice as sd
import soundfile as sf
import librosa
import librosa.display
import torchaudio
import torchaudio.transforms as T
import tkinter as tk
from tkinter import filedialog, messagebox, simpledialog
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib.pyplot as plt
import numpy as np
import threading
import time
import os
import sys
import pandas as pd
import scipy.signal as signal
import xlsxwriter

# Set environment variable to allow OpenMP runtime duplication
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

class AudioApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Audio Recorder and Analyzer")
        self.root.geometry(f"600x{round((2/3)*self.root.winfo_screenheight())}")  # Set height to match screen height

        self.recording = False
        self.audio_data = None
        self.samplerate = 44100
        self.loaded_file_path = None
        self.playing = False
        self.paused = False
        self.playback_thread = None
        self.playback_position = 0
        self.process_conditions = ""

        self.create_widgets()

        # ì°½ ë‹«ê¸° ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

        # Initialize metadata file
        self.exe_dir = os.path.dirname(os.path.abspath(sys.executable if getattr(sys, 'frozen', False) else __file__))
        self.metadata_file = os.path.join(self.exe_dir, "metadata.csv")
        if not os.path.exists(self.metadata_file):
            pd.DataFrame(columns=["filename", "process_conditions"]).to_csv(self.metadata_file, index=False)

    def create_widgets(self):
        self.process_label = tk.Label(self.root, text="3D Printing Process Conditions:", font=("Arial", 10))
        self.process_label.pack(pady=5)

        self.process_entry = tk.Entry(self.root, width=50)
        self.process_entry.pack(pady=5)

        self.record_button = tk.Button(self.root, text="Start Recording", command=self.start_recording, width=20)
        self.record_button.pack(pady=10)

        self.stop_button = tk.Button(self.root, text="Stop Recording", command=self.stop_recording, width=20)
        self.stop_button.pack(pady=10)

        self.load_button = tk.Button(self.root, text="Load Audio File", command=self.load_audio, width=20)
        self.load_button.pack(pady=10)

        self.playback_label = tk.Label(self.root, text="No file loaded.", font=("Arial", 10))
        self.playback_label.pack(pady=10)

        control_frame = tk.Frame(self.root)
        control_frame.pack(pady=5)

        self.play_button = tk.Button(control_frame, text="Play", command=self.play_audio, width=10)
        self.play_button.pack(side=tk.LEFT, padx=5)

        self.pause_button = tk.Button(control_frame, text="Pause", command=self.pause_audio, width=10)
        self.pause_button.pack(side=tk.LEFT, padx=5)

        self.stop_playback_button = tk.Button(control_frame, text="Stop", command=self.stop_audio, width=10)
        self.stop_playback_button.pack(side=tk.LEFT, padx=5)

        self.playback_bar = tk.Scale(self.root, from_=0, to=100, orient=tk.HORIZONTAL, length=400, resolution=0.01, state=tk.DISABLED)
        self.playback_bar.pack(pady=10)

        self.audio_graph_frame = tk.Frame(self.root, height=200)
        self.audio_graph_frame.pack(pady=10, fill=tk.BOTH, expand=False)

        self.buttons_frame = tk.Frame(self.root)
        self.buttons_frame.pack(pady=0)

        self.equalize_button = tk.Button(self.root, text="Equalize Audio", command=self.equalize_audio, width=20)
        self.equalize_button.pack(pady=10)

        self.hpss_button = tk.Button(self.root, text="Apply HPSS", command=self.apply_hpss, width=20)
        self.hpss_button.pack(pady=10)

        self.fft_button = tk.Button(self.root, text="FFT Analysis", command=self.fft_analysis, width=20)
        self.fft_button.pack(pady=10)

        self.spectrogram_button = tk.Button(self.root, text="Spectrogram", command=self.spectrogram_analysis, width=20)
        self.spectrogram_button.pack(pady=10)


    def start_recording(self):
        if not self.recording:
            self.process_conditions = self.process_entry.get()
            if not self.process_conditions:
                messagebox.showwarning("Warning", "Please enter process conditions before recording.")
                return

            self.recording = True
            self.audio_data = []
            self.start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
            self.update_recording_timer()  # íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ

            self.stream = sd.InputStream(samplerate=self.samplerate, channels=1, callback=self.audio_callback)
            self.stream.start()

    def update_recording_timer(self):
        if self.recording:
            elapsed_time = time.time() - self.start_time
            self.record_button.config(text=f"Recording... {elapsed_time:.1f} sec")
            self.root.after(100, self.update_recording_timer)  # 0.1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
        else:
            self.record_button.config(text="Start Recording")

    def audio_callback(self, indata, frames, time, status):
        if self.recording:
            self.audio_data.append(indata.copy())

    def stop_recording(self):
        if self.recording:
            self.recording = False
            self.stream.stop()
            self.stream.close()
            self.audio_data = np.concatenate(self.audio_data, axis=0)
            self.record_button.config(text="Start Recording")  # ë²„íŠ¼ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”

            # Ask the user where to save the recording
            save_path = filedialog.asksaveasfilename(defaultextension=".wav", filetypes=[("WAV files", "*.wav")], title="Save Recording")
            if save_path:
                sf.write(save_path, self.audio_data, self.samplerate)

                # Extract filename from save_path
                filename = os.path.basename(save_path)

                # Append metadata to the CSV file
                metadata = pd.DataFrame([[filename, self.process_conditions]], columns=["filename", "process_conditions"])
                metadata.to_csv(self.metadata_file, mode='a', header=False, index=False)

                messagebox.showinfo("Save", f"Recording saved as {filename} and process conditions added to metadata.")

    def load_audio(self):
        file_path = filedialog.askopenfilename(filetypes=[("Audio Files", "*.wav")])
        if file_path:
            self.audio_data, self.samplerate = librosa.load(file_path, sr=None, mono=True)
            self.loaded_file_path = file_path
            duration = len(self.audio_data) / self.samplerate
            self.playback_label.config(text=f"Loaded File: {file_path.split('/')[-1]}")
            self.playback_bar.config(state=tk.NORMAL, from_=0, to=duration, resolution=0.01, label=f"0 / {duration:.2f} sec")
            # messagebox.showinfo("Load", "Audio file loaded successfully.")
            
            self.display_audio_waveform()

    def display_audio_waveform(self):
        for widget in self.audio_graph_frame.winfo_children():
            widget.destroy()

        fig, ax = plt.subplots(figsize=(8, 2), constrained_layout=True)  # Ensure axis labels are visible  # Increase height for better visibility of labels  # Reduce height for fixed placement
        librosa.display.waveshow(self.audio_data, sr=self.samplerate, ax=ax)
        ax.set(title="Waveform", xlabel="Time (s)", ylabel="Amplitude")

        canvas = FigureCanvasTkAgg(fig, master=self.audio_graph_frame)
        canvas_widget = canvas.get_tk_widget()
        canvas_widget.pack()
        canvas.draw()

    def play_audio(self):
        if self.audio_data is not None:
            if not self.playing:
                self.playing = True
                self.paused = False
                self.playback_thread = threading.Thread(target=self.playback)
                self.playback_thread.start()
            elif self.paused:
                self.paused = False
                self.playing = True
        else:
            messagebox.showwarning("Warning", "No audio file loaded to play.")

    def pause_audio(self):
        if self.playing:
            self.paused = True
            self.playing = False
            sd.stop()

    def stop_audio(self):
        """ì˜¤ë””ì˜¤ ì¬ìƒì„ ì™„ì „íˆ ì •ì§€í•˜ê³  0ì´ˆë¶€í„° ë‹¤ì‹œ ì‹œì‘í•˜ë„ë¡ ì„¤ì •"""
        if self.playing or self.paused:
            self.playing = False
            self.paused = False
            self.playback_position = 0  # ì¬ìƒ ìœ„ì¹˜ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ˆê¸°í™”
            sd.stop()
            self.playback_bar.set(0)
            self.playback_bar.config(label=f"0 / {len(self.audio_data) / self.samplerate:.2f} sec")


    def playback(self):
        try:
            start_index = int(self.playback_position * self.samplerate)
            duration = len(self.audio_data) / self.samplerate
            sd.play(self.audio_data[start_index:], self.samplerate)
            start_time = time.time() - self.playback_position

            while self.playing and self.playback_position < duration:
                if self.paused:
                    sd.stop()
                    break

                elapsed_time = time.time() - start_time
                self.playback_position = elapsed_time
                self.playback_bar.set(self.playback_position)
                self.playback_bar.config(label=f"{self.playback_position:.2f} / {duration:.2f} sec")
                time.sleep(0.01)

            if not self.paused:
                self.playing = False
                self.playback_position = 0
                self.playback_bar.set(0)
                self.playback_bar.config(label=f"0 / {duration:.2f} sec")

        except Exception as e:
            messagebox.showerror("Error", f"Playback error: {e}")
        finally:
            self.playing = False

    def apply_equalization(self, audio, sr):
        """
        íŠ¹ì • ì£¼íŒŒìˆ˜ ëŒ€ì—­ì˜ gainì„ ì ìš©í•˜ì—¬ equalization ìˆ˜í–‰
        """
        gains = {
            (0, 1000): 0.5,   # ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ê°ì†Œ
            (1000, 5000): 1.5, # ì¤‘ì£¼íŒŒìˆ˜ ëŒ€ì—­ ê°•ì¡°
            (5000, 20000): 2.0 # ê³ ì£¼íŒŒìˆ˜ ëŒ€ì—­ ê°•ì¡°
        }
        
        output = np.zeros_like(audio)
        
        for (low, high), gain in gains.items():
            low = max(low, 1e-6)  # 0Hz ë°©ì§€
            sos = signal.butter(2, [low / (sr / 2), high / (sr / 2)], btype='bandpass', output='sos')
            filtered = signal.sosfilt(sos, audio) * gain
            output += filtered
        
        return output

    def equalize_audio(self):
        """Equalization í›„ ì›ë³¸ê³¼ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³ , -eq íŒŒì¼ë¡œ ì €ì¥"""
        if self.audio_data is None:
            messagebox.showwarning("Warning", "No audio data available for Equalization.")
            return

        # Equalization ì ìš©
        equalized_audio = self.apply_equalization(self.audio_data, self.samplerate)

        # **íŒŒì¼ ìë™ ì €ì¥ (-eq ì¶”ê°€)**
        if self.loaded_file_path:
            file_dir, file_name = os.path.split(self.loaded_file_path)
            file_base, file_ext = os.path.splitext(file_name)
            eq_file_name = f"{file_base}-eq{file_ext}"
            eq_file_path = os.path.join(file_dir, eq_file_name)

            sf.write(eq_file_path, equalized_audio, self.samplerate)  # Equalized íŒŒì¼ ì €ì¥
            messagebox.showinfo("Saved", f"Equalized file saved as: {eq_file_path}")

        # **Equalization í›„ NaNì´ë‚˜ 0ê°’ ë°©ì§€**
        if np.all(equalized_audio == 0):
            messagebox.showerror("Error", "Equalization resulted in all zero values!")
            return
        equalized_audio = np.nan_to_num(equalized_audio)

        # **ìƒˆë¡œìš´ Tkinter ì°½ ìƒì„±**
        new_window = tk.Toplevel(self.root)
        new_window.title("Equalization Analysis")
        new_window.geometry("1200x800")

        fig, axs = plt.subplots(3, 2, figsize=(12, 10))  # 3í–‰ 2ì—´ ì„œë¸Œí”Œë¡¯
        time_axis = np.linspace(0, len(self.audio_data) / self.samplerate, len(self.audio_data))

        # (1) Waveform ë¹„êµ
        axs[0, 0].plot(time_axis, self.audio_data, label="Raw Audio", alpha=0.7)
        axs[0, 1].plot(time_axis, equalized_audio, label="Equalized Audio", alpha=0.7)
        axs[0, 0].set_title("Waveform (Raw)")
        axs[0, 1].set_title("Waveform (Equalized)")

        max_amplitude = max(np.max(np.abs(self.audio_data)), np.max(np.abs(equalized_audio)))
        axs[0, 0].set_ylim(-max_amplitude, max_amplitude)
        axs[0, 1].set_ylim(-max_amplitude, max_amplitude)

        # (2) FFT ë¹„êµ
        fft_raw = np.fft.fft(self.audio_data)
        fft_eq = np.fft.fft(equalized_audio)
        freqs = np.fft.fftfreq(len(self.audio_data), 1 / self.samplerate)

        axs[1, 0].plot(freqs[:len(freqs)//2], np.abs(fft_raw[:len(freqs)//2]), label="Raw FFT", alpha=0.7)
        axs[1, 1].plot(freqs[:len(freqs)//2], np.abs(fft_eq[:len(freqs)//2]), label="Equalized FFT", alpha=0.7)
        axs[1, 0].set_xscale("log")
        axs[1, 1].set_xscale("log")

        max_fft_magnitude = max(np.max(np.abs(fft_raw)), np.max(np.abs(fft_eq)))
        axs[1, 0].set_ylim(0, max_fft_magnitude)
        axs[1, 1].set_ylim(0, max_fft_magnitude)

        # (3) Spectrogram ë¹„êµ (vmin, vmax ìë™ ì¡°ì •)
        _, _, _, im1 = axs[2, 0].specgram(self.audio_data, Fs=self.samplerate, NFFT=1024, cmap="magma")
        _, _, _, im2 = axs[2, 1].specgram(equalized_audio, Fs=self.samplerate, NFFT=1024, cmap="cool")

        vmin = min(im1.get_clim()[0], im2.get_clim()[0])  # ìµœì†Œê°’
        vmax = max(im1.get_clim()[1], im2.get_clim()[1])  # ìµœëŒ€ê°’

        im1.set_clim(vmin, vmax)
        im2.set_clim(vmin, vmax)

        axs[2, 0].set_title("Spectrogram (Raw)")
        axs[2, 1].set_title("Spectrogram (Equalized)")

        plt.tight_layout()
        canvas = FigureCanvasTkAgg(fig, master=new_window)
        canvas.get_tk_widget().pack()
        canvas.draw()

    def apply_hpss(self):
        """Equalized ì˜¤ë””ì˜¤ì— HPSS ì ìš© í›„ ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¹„êµ ê·¸ë˜í”„ë¥¼ ìƒì„±"""
        if self.audio_data is None or self.loaded_file_path is None:
            messagebox.showwarning("Warning", "No audio data available for HPSS.")
            return

        # **Equalized íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°**
        file_dir, file_name = os.path.split(self.loaded_file_path)
        file_base, file_ext = os.path.splitext(file_name)
        eq_file_name = f"{file_base}-eq{file_ext}"
        eq_file_path = os.path.join(file_dir, eq_file_name)

        if not os.path.exists(eq_file_path):
            messagebox.showerror("Error", f"Equalized file not found: {eq_file_path}")
            return

        eq_audio, eq_samplerate = librosa.load(eq_file_path, sr=None, mono=True)

        # **HPSS ì ìš©**
        harmonic, percussive = librosa.effects.hpss(eq_audio)
        hpss_audio = harmonic  # í•˜ëª¨ë‹‰ ì„±ë¶„ë§Œ ì‚¬ìš©

        # **HPSS íŒŒì¼ ì €ì¥ (-eq-hpss ì¶”ê°€)**
        hpss_file_name = f"{file_base}-eq-hpss{file_ext}"
        hpss_file_path = os.path.join(file_dir, hpss_file_name)

        sf.write(hpss_file_path, hpss_audio, eq_samplerate)  # HPSS ì ìš©ëœ íŒŒì¼ ì €ì¥
        messagebox.showinfo("Saved", f"HPSS-applied file saved as: {hpss_file_path}")

        # **ìƒˆë¡œìš´ Tkinter ì°½ ìƒì„±**
        new_window = tk.Toplevel(self.root)
        new_window.title("HPSS Analysis")
        new_window.geometry("1200x800")

        fig, axs = plt.subplots(3, 2, figsize=(12, 10))  # 3í–‰ 2ì—´ ì„œë¸Œí”Œë¡¯
        time_axis = np.linspace(0, len(eq_audio) / eq_samplerate, len(eq_audio))

        # (1) Waveform ë¹„êµ
        axs[0, 0].plot(time_axis, eq_audio, label="Equalized Audio", alpha=0.7)
        axs[0, 1].plot(time_axis, hpss_audio, label="Equalized & HPSS Audio", alpha=0.7)
        axs[0, 0].set_title("Waveform (Equalized)")
        axs[0, 1].set_title("Waveform (Equalized & HPSS)")

        max_amplitude = max(np.max(np.abs(eq_audio)), np.max(np.abs(hpss_audio)))
        axs[0, 0].set_ylim(-max_amplitude, max_amplitude)
        axs[0, 1].set_ylim(-max_amplitude, max_amplitude)

        # (2) FFT ë¹„êµ
        fft_eq = np.fft.fft(eq_audio)
        fft_hpss = np.fft.fft(hpss_audio)
        freqs = np.fft.fftfreq(len(eq_audio), 1 / eq_samplerate)

        axs[1, 0].plot(freqs[:len(freqs)//2], np.abs(fft_eq[:len(freqs)//2]), label="Equalized FFT", alpha=0.7)
        axs[1, 1].plot(freqs[:len(freqs)//2], np.abs(fft_hpss[:len(freqs)//2]), label="Equalized & HPSS FFT", alpha=0.7)
        axs[1, 0].set_xscale("log")
        axs[1, 1].set_xscale("log")

        max_fft_magnitude = max(np.max(np.abs(fft_eq)), np.max(np.abs(fft_hpss)))
        axs[1, 0].set_ylim(0, max_fft_magnitude)
        axs[1, 1].set_ylim(0, max_fft_magnitude)

        # (3) Spectrogram ë¹„êµ (vmin, vmax ìë™ ì¡°ì •)
        _, _, _, im1 = axs[2, 0].specgram(eq_audio, Fs=eq_samplerate, NFFT=1024, cmap="magma")
        _, _, _, im2 = axs[2, 1].specgram(hpss_audio, Fs=eq_samplerate, NFFT=1024, cmap="cool")

        vmin = min(im1.get_clim()[0], im2.get_clim()[0])  # ìµœì†Œê°’
        vmax = max(im1.get_clim()[1], im2.get_clim()[1])  # ìµœëŒ€ê°’

        im1.set_clim(vmin, vmax)
        im2.set_clim(vmin, vmax)

        axs[2, 0].set_title("Spectrogram (Equalized)")
        axs[2, 1].set_title("Spectrogram (Equalized & HPSS)")

        plt.tight_layout()
        canvas = FigureCanvasTkAgg(fig, master=new_window)
        canvas.get_tk_widget().pack()
        canvas.draw()

    def fft_analysis(self):
        """HPSSê¹Œì§€ ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ FFT ë¶„ì„ ìˆ˜í–‰ ë° ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€"""
        
        if self.loaded_file_path is None:
            messagebox.showwarning("Warning", "No audio file loaded for FFT analysis.")
            return

        # **HPSS íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (-eq-hpss.wav)**
        file_dir, file_name = os.path.split(self.loaded_file_path)
        file_base, file_ext = os.path.splitext(file_name)
        hpss_file_name = f"{file_base}-eq-hpss{file_ext}"
        hpss_file_path = os.path.join(file_dir, hpss_file_name)

        if not os.path.exists(hpss_file_path):
            messagebox.showerror("Error", f"HPSS-processed file not found: {hpss_file_path}")
            return

        # HPSS ì ìš©ëœ ì˜¤ë””ì˜¤ ë¡œë“œ
        audio_data, samplerate = librosa.load(hpss_file_path, sr=None, mono=True)

        # FFT ê³„ì‚°
        N = len(audio_data)
        T = 1.0 / samplerate
        yf = np.fft.fft(audio_data)
        xf = np.fft.fftfreq(N, T)[:N//2]  # ì–‘ì˜ ì£¼íŒŒìˆ˜ ì„±ë¶„ë§Œ ì‚¬ìš©
        magnitude = 2.0/N * np.abs(yf[:N//2])  # ì§„í­ ê³„ì‚°

        # ê°€ì¥ ê°•í•œ ì£¼íŒŒìˆ˜ ì°¾ê¸°
        from scipy.signal import find_peaks
        peaks, _ = find_peaks(magnitude, height=0.00001)  # íŠ¹ì • ì§„í­ ì´ìƒì¸ ì£¼íŒŒìˆ˜ ì°¾ê¸°
        peak_magnitudes = magnitude[peaks]

        # ìƒìœ„ 5ê°œ ì£¼íŒŒìˆ˜ ì°¾ê¸°
        top_n = 5
        top_indices = np.argsort(peak_magnitudes)[-top_n:][::-1]  # ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        top_freqs = xf[peaks][top_indices]  # ìƒìœ„ ì£¼íŒŒìˆ˜ë“¤
        top_amplitudes = peak_magnitudes[top_indices]  # ìƒìœ„ ì§„í­ë“¤

        # ìƒˆë¡œìš´ ì°½ ìƒì„±
        new_window = tk.Toplevel(self.root)
        new_window.title("FFT Analysis (HPSS Processed)")
        new_window.geometry("800x500")

        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.plot(xf, magnitude, label="FFT Spectrum")
        ax.set_xscale("log")  # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©
        ax.set(title="FFT Analysis (HPSS Processed)", xlabel="Frequency (Hz)", ylabel="Amplitude")

        # ìƒìœ„ ì£¼íŒŒìˆ˜ ê°•ì¡° í‘œì‹œ
        for i in range(len(top_freqs)):
            ax.axvline(x=top_freqs[i], color='r', linestyle='--', label=f'Peak {i+1}: {top_freqs[i]:.1f} Hz')

        ax.legend()

        # Tkinterì—ì„œ ê·¸ë˜í”„ í‘œì‹œ
        canvas = FigureCanvasTkAgg(fig, master=new_window)
        canvas.get_tk_widget().pack()

        # ì €ì¥ ë²„íŠ¼ ì¶”ê°€
        button_frame = tk.Frame(new_window)
        button_frame.pack(pady=10)

        # **CSV ì €ì¥ í•¨ìˆ˜**
        def save_fft_data():
            save_path = filedialog.asksaveasfilename(defaultextension=".csv",
                                                    filetypes=[("CSV files", "*.csv")],
                                                    title="Save FFT Data")
            if save_path:
                fft_data = pd.DataFrame({"Frequency (Hz)": xf, "Magnitude": magnitude})
                fft_data.to_csv(save_path, index=False)
                messagebox.showinfo("Save", f"FFT Data saved as {save_path}")

        # **PNG ì €ì¥ í•¨ìˆ˜**
        def save_fft_graph():
            save_path = filedialog.asksaveasfilename(defaultextension=".png",
                                                    filetypes=[("PNG files", "*.png")],
                                                    title="Save FFT Graph")
            if save_path:
                fig.savefig(save_path)
                messagebox.showinfo("Save", f"FFT Graph saved as {save_path}")

        # CSV ì €ì¥ ë²„íŠ¼ ì¶”ê°€
        save_data_button = tk.Button(button_frame, text="Save Data to CSV", command=save_fft_data, width=20)
        save_data_button.pack(side=tk.LEFT, padx=10)

        # PNG ì €ì¥ ë²„íŠ¼ ì¶”ê°€
        save_graph_button = tk.Button(button_frame, text="Save Graph as PNG", command=save_fft_graph, width=20)
        save_graph_button.pack(side=tk.RIGHT, padx=10)

        canvas.draw()

        # ê²°ê³¼ ì¶œë ¥
        print("ğŸ”¹ HPSS ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ê¸°ì¤€ ì£¼ìš” ì£¼íŒŒìˆ˜ ëª©ë¡:")
        for i in range(len(top_freqs)):
            print(f"{i+1}ï¸âƒ£  {top_freqs[i]:.2f} Hz, ì§„í­: {top_amplitudes[i]:.6f}")

        return top_freqs, top_amplitudes  # ì£¼ìš” ì£¼íŒŒìˆ˜ ë° ì§„í­ ë°˜í™˜



    def spectrogram_analysis(self):
        """Raw, Equalized, HPSSëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Spectrogram ë¶„ì„ ë° ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€"""

        if self.loaded_file_path is None:
            messagebox.showwarning("Warning", "No audio file loaded for Spectrogram analysis.")
            return

        # **íŒŒì¼ ê²½ë¡œ ì„¤ì •**
        file_dir, file_name = os.path.split(self.loaded_file_path)
        file_base, file_ext = os.path.splitext(file_name)

        # ì›ë³¸ (Raw) ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°
        raw_audio, samplerate = librosa.load(self.loaded_file_path, sr=None, mono=True)

        # Equalized ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸° (-eq.wav)
        eq_file_name = f"{file_base}-eq{file_ext}"
        eq_file_path = os.path.join(file_dir, eq_file_name)

        if os.path.exists(eq_file_path):
            eq_audio, _ = librosa.load(eq_file_path, sr=None, mono=True)
        else:
            eq_audio = None  # Equalized íŒŒì¼ì´ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬

        # HPSS ì ìš©ëœ ì˜¤ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸° (-eq-hpss.wav)
        hpss_file_name = f"{file_base}-eq-hpss{file_ext}"
        hpss_file_path = os.path.join(file_dir, hpss_file_name)

        if os.path.exists(hpss_file_path):
            hpss_audio, _ = librosa.load(hpss_file_path, sr=None, mono=True)
        else:
            hpss_audio = None  # HPSS íŒŒì¼ì´ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬

        # **ìƒˆë¡œìš´ Tkinter ì°½ ìƒì„±**
        new_window = tk.Toplevel(self.root)
        new_window.title("Spectrogram Analysis (Raw vs. Equalized vs. HPSS)")
        new_window.geometry("1200x900")  # ì°½ í¬ê¸° í‚¤ìš°ê¸°

        # **ë²„íŠ¼ì„ ì¶”ê°€í•  í”„ë ˆì„ ìƒì„±**
        button_frame = tk.Frame(new_window)
        button_frame.pack(side=tk.BOTTOM, pady=10, fill=tk.X)

        # **Spectrogram ê·¸ë˜í”„ ìƒì„±**
        fig, axs = plt.subplots(3, 1, figsize=(12, 10))  # 3ê°œì˜ Spectrogram ë¹„êµ

        # **(1) Raw Audio Spectrogram**
        D_raw = librosa.amplitude_to_db(np.abs(librosa.stft(raw_audio)), ref=np.max)
        img1 = librosa.display.specshow(D_raw, sr=samplerate, x_axis='time', y_axis='log', ax=axs[0])
        axs[0].set(title="Spectrogram (Raw Audio)")
        fig.colorbar(img1, ax=axs[0], format="%+2.0f dB")

        # **(2) Equalized Audio Spectrogram**
        if eq_audio is not None:
            D_eq = librosa.amplitude_to_db(np.abs(librosa.stft(eq_audio)), ref=np.max)
            img2 = librosa.display.specshow(D_eq, sr=samplerate, x_axis='time', y_axis='log', ax=axs[1])
            axs[1].set(title="Spectrogram (Equalized Audio)")
            fig.colorbar(img2, ax=axs[1], format="%+2.0f dB")
        else:
            axs[1].text(0.5, 0.5, "Equalized Audio Not Found", fontsize=12, ha="center", va="center")

        # **(3) HPSS Audio Spectrogram**
        if hpss_audio is not None:
            D_hpss = librosa.amplitude_to_db(np.abs(librosa.stft(hpss_audio)), ref=np.max)
            img3 = librosa.display.specshow(D_hpss, sr=samplerate, x_axis='time', y_axis='log', ax=axs[2])
            axs[2].set(title="Spectrogram (HPSS Processed Audio)")
            fig.colorbar(img3, ax=axs[2], format="%+2.0f dB")
        else:
            axs[2].text(0.5, 0.5, "HPSS Processed Audio Not Found", fontsize=12, ha="center", va="center")

        plt.tight_layout()

        # **Tkinter Canvas ì¶”ê°€ (ê·¸ë˜í”„ ë„ìš°ê¸°)**
        canvas = FigureCanvasTkAgg(fig, master=new_window)
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)  # ë²„íŠ¼ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í™•ì¥

        # **PNG ì €ì¥ í•¨ìˆ˜**
        def save_spectrogram_graph():
            save_path = filedialog.asksaveasfilename(defaultextension=".png",
                                                    filetypes=[("PNG files", "*.png")],
                                                    title="Save Spectrogram Graph")
            if save_path:
                fig.savefig(save_path)
                messagebox.showinfo("Save", f"Spectrogram Graph saved as {save_path}")

        # **CSV ì €ì¥ í•¨ìˆ˜**
        def save_spectrogram_data():
            save_path = filedialog.asksaveasfilename(defaultextension=".csv",
                                                    filetypes=[("CSV files", "*.csv")],
                                                    title="Save Spectrogram Data")
            if save_path:
                # ì‹œê°„-ì£¼íŒŒìˆ˜-ì§„í­ ë°ì´í„° ì €ì¥
                times = librosa.times_like(D_raw, sr=samplerate)
                freqs = librosa.fft_frequencies(sr=samplerate)

                # ë°ì´í„° í”„ë ˆì„ ìƒì„±
                spectrogram_data = pd.DataFrame(D_raw, index=freqs, columns=times)
                spectrogram_data.to_csv(save_path, index=True)
                messagebox.showinfo("Save", f"Spectrogram Data saved as {save_path}")

        # **ë²„íŠ¼ ì¶”ê°€**
        save_graph_button = tk.Button(button_frame, text="Save Graph as PNG", command=save_spectrogram_graph, width=25)
        save_graph_button.pack(side=tk.LEFT, padx=10)

        save_data_button = tk.Button(button_frame, text="Save Data to CSV", command=save_spectrogram_data, width=25)
        save_data_button.pack(side=tk.RIGHT, padx=10)

        canvas.draw()


    def on_closing(self):
        """ì°½ì´ ë‹«í ë•Œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜"""
        if self.playing:
            self.playing = False  # ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ì§€
            sd.stop()  # ì‚¬ìš´ë“œ ì •ì§€
            time.sleep(0.1)  # ì•½ê°„ì˜ ì§€ì—°ìœ¼ë¡œ ì•ˆì „ ì¢…ë£Œ

        if self.playback_thread and self.playback_thread.is_alive():
            self.playback_thread.join(timeout=1)  # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°

        self.root.quit()  # Tkinter ë£¨í”„ ì¢…ë£Œ
        self.root.destroy()  # ëª¨ë“  GUI ìš”ì†Œ ì œê±°
        print("í”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    def save_data_to_excel(self, data, filename="graph_data.xlsx"):
        """
        ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ pandasë¥¼ ì‚¬ìš©í•˜ì—¬ Excel íŒŒì¼ë¡œ ì €ì¥ (openpyxl ì—†ì´)
        """
        save_path = filedialog.asksaveasfilename(defaultextension=".xlsx",
                                                filetypes=[("Excel files", "*.xlsx")],
                                                title="Save Data as Excel")
        if save_path:
            df = pd.DataFrame(data)
            df.to_excel(save_path, index=False, engine="xlsxwriter")  # xlsxwriter ì—”ì§„ ì‚¬ìš©
            messagebox.showinfo("Save", f"Data saved as {save_path}")


    def save_graph_as_image(self, fig):
        """
        ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
        """
        save_path = filedialog.asksaveasfilename(defaultextension=".png",
                                                filetypes=[("PNG files", "*.png"), ("JPEG files", "*.jpg")],
                                                title="Save Graph as Image")
        if save_path:
            fig.savefig(save_path)
            messagebox.showinfo("Save", f"Graph saved as {save_path}")

    def add_save_buttons(self, parent_window, fig, data):
        """
        ê·¸ë˜í”„ ì°½ì— ë°ì´í„° ì €ì¥ ë° ê·¸ë˜í”„ ì €ì¥ ë²„íŠ¼ ì¶”ê°€
        """
        button_frame = tk.Frame(parent_window)
        button_frame.pack(pady=10)

        # ë°ì´í„° ì €ì¥ ë²„íŠ¼
        save_data_button = tk.Button(button_frame, text="Save Data to Excel",
                                    command=lambda: self.save_data_to_excel(data),
                                    width=25)
        save_data_button.pack(pady=5)

        # ê·¸ë˜í”„ ì €ì¥ ë²„íŠ¼
        save_graph_button = tk.Button(button_frame, text="Save Graph as Image",
                                    command=lambda: self.save_graph_as_image(fig),
                                    width=25)
        save_graph_button.pack(pady=5)


if __name__ == "__main__":
    print("Initializing the GUI...")

    # ë””ë ‰í† ë¦¬ ì„¤ì •: ê²½ë¡œ ë¬¸ì œ ë°©ì§€
    try:
        exe_dir = os.path.dirname(os.path.abspath(sys.executable if getattr(sys, 'frozen', False) else __file__))
        os.chdir(exe_dir)
        print(f"Current working directory: {exe_dir}")
    except Exception as e:
        print(f"Failed to change directory: {e}")

    try:
        # GUI ì´ˆê¸°í™”
        root = tk.Tk()
        app = AudioApp(root)
        print("Starting the GUI application.")
        root.mainloop()
    except Exception as e:
        print(f"Error occurred during GUI initialization: {e}")

